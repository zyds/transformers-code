{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer åŸºæœ¬ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§æ¢¦æƒ³!\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1 åŠ è½½ä¸Žä¿å­˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä»ŽHuggingFaceåŠ è½½ï¼Œè¾“å…¥æ¨¡åž‹åç§°ï¼Œå³å¯åŠ è½½å¯¹äºŽçš„åˆ†è¯å™¨\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./roberta_tokenizer\\\\tokenizer_config.json',\n",
       " './roberta_tokenizer\\\\special_tokens_map.json',\n",
       " './roberta_tokenizer\\\\vocab.txt',\n",
       " './roberta_tokenizer\\\\added_tokens.json',\n",
       " './roberta_tokenizer\\\\tokenizer.json')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenizer ä¿å­˜åˆ°æœ¬åœ°\n",
    "tokenizer.save_pretrained(\"./roberta_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ä»Žæœ¬åœ°åŠ è½½tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./roberta_tokenizer/\")\n",
    "tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2 å¥å­åˆ†è¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['å¼±', 'å°', 'çš„', 'æˆ‘', 'ä¹Ÿ', 'æœ‰', 'å¤§', 'æ¢¦', 'æƒ³', '!']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer.tokenize(sen)\n",
    "tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step3 æŸ¥çœ‹è¯å…¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'##8': 8156,\n",
       " '##è›Š': 19084,\n",
       " 'ç—™': 4577,\n",
       " 'é°': 7106,\n",
       " 'ç ': 4772,\n",
       " '141': 9554,\n",
       " 'é¡”': 7543,\n",
       " 'h2': 12212,\n",
       " 'west': 8520,\n",
       " '##á…§': 13474,\n",
       " '##å®³': 15211,\n",
       " '3mm': 12064,\n",
       " '##â€¿': 13509,\n",
       " 'é¾': 7984,\n",
       " 'ï¼…': 8017,\n",
       " 'æ·–': 3904,\n",
       " '##ç¼•': 18412,\n",
       " '##æ‚': 16382,\n",
       " '##ã„ž': 13717,\n",
       " '##èµ›': 19669,\n",
       " '##éƒ«': 20014,\n",
       " '##ith': 11440,\n",
       " '##ç‰': 17452,\n",
       " '##tle': 11283,\n",
       " 'ç›–': 4667,\n",
       " 'general': 11568,\n",
       " '##è¦º': 19278,\n",
       " '##ç¿…': 18477,\n",
       " 'focus': 11452,\n",
       " 'æ¢­': 3460,\n",
       " '##ç˜˜': 17657,\n",
       " 'é…ª': 6991,\n",
       " 'é£™': 7604,\n",
       " '##è°˜': 19519,\n",
       " '##é¹‚': 20954,\n",
       " 'â…°': 363,\n",
       " 'é¡½': 7559,\n",
       " 'å³´': 2293,\n",
       " 'é‚¦': 6930,\n",
       " '##ã‚»': 13686,\n",
       " '711': 12565,\n",
       " 'éº´': 7933,\n",
       " '##æ©¼': 16645,\n",
       " 'netscape': 8691,\n",
       " '##lock': 11248,\n",
       " 'å“': 1405,\n",
       " 'xyz': 11266,\n",
       " 'å—“': 1624,\n",
       " '##cept': 11877,\n",
       " 'é™…': 7354,\n",
       " 'à¼‹': 286,\n",
       " '##art': 9528,\n",
       " 'æŠ›': 2837,\n",
       " '##host': 12227,\n",
       " '##ã‚«ãƒ¼': 10175,\n",
       " '1350': 12809,\n",
       " 'talk2yam': 8767,\n",
       " '##97': 9410,\n",
       " 'é ': 7479,\n",
       " '##ï¼': 8569,\n",
       " '7x24': 12486,\n",
       " '##ads': 12514,\n",
       " '##Ø¨': 13428,\n",
       " '##éµ‘': 20921,\n",
       " '##åŽ¥': 14392,\n",
       " '##åœ¨': 14819,\n",
       " '##å¥³': 15014,\n",
       " '##ç™»': 17690,\n",
       " 'æ‚¬': 2647,\n",
       " '##æ‘Ÿ': 16095,\n",
       " '##â”£': 13585,\n",
       " 'é³Œ': 7845,\n",
       " 'çš–': 4646,\n",
       " '[unused2]': 2,\n",
       " 'kanshu': 13236,\n",
       " '##ot': 8783,\n",
       " 'è„£': 5560,\n",
       " '[unused6]': 6,\n",
       " '##et': 8418,\n",
       " 'ç”¯': 4505,\n",
       " '##ç¶²': 18263,\n",
       " '##çº²': 18343,\n",
       " '##è³“': 19597,\n",
       " 'é¢ˆ': 7568,\n",
       " 'â…±': 364,\n",
       " 'ç¹«': 5258,\n",
       " '##ãƒªãƒ¼': 10535,\n",
       " 'æ”': 3109,\n",
       " '##æ“‚': 16133,\n",
       " 'gmp': 10821,\n",
       " 'è²©': 6516,\n",
       " 'è´©': 6575,\n",
       " 'é “': 7524,\n",
       " 'cheese': 11387,\n",
       " 'cover': 12555,\n",
       " '##ç³¾': 18201,\n",
       " '##æ‰': 15855,\n",
       " 'æ¥·': 3514,\n",
       " 'è¶£': 6637,\n",
       " '##åŸƒ': 14869,\n",
       " '##çœº': 17762,\n",
       " 'æµª': 3857,\n",
       " '##è¶£': 19694,\n",
       " '##é£¨': 20667,\n",
       " '##è³ž': 19599,\n",
       " 'çˆ¸': 4268,\n",
       " '##62': 9290,\n",
       " 'é—¢': 7304,\n",
       " 'éœŠ': 7451,\n",
       " '##è†›': 18662,\n",
       " '##æž„': 16411,\n",
       " 'å˜œ': 1659,\n",
       " '##å‚': 14045,\n",
       " '##ã„ã¾ã™': 9184,\n",
       " '##å’': 14528,\n",
       " 'paypal': 8657,\n",
       " 'è€³': 5455,\n",
       " '188': 9460,\n",
       " 'fairmont': 12208,\n",
       " '##ç©Ž': 18006,\n",
       " 'è­¦': 6356,\n",
       " 'æŠ¢': 2843,\n",
       " '##å ‡': 14889,\n",
       " '##ä¾¿': 13969,\n",
       " 'glass': 12535,\n",
       " 'ä¿š': 923,\n",
       " 'åƒµ': 1018,\n",
       " 'å‹': 1233,\n",
       " 'å§‘': 1996,\n",
       " 'é“®': 7209,\n",
       " '##our': 9832,\n",
       " 'ã‚': 582,\n",
       " '##çµ¹': 18248,\n",
       " '##å³‡': 15337,\n",
       " '##èª¤': 19356,\n",
       " 'å»¿': 2457,\n",
       " 'ã‚ã‚Šãª': 13022,\n",
       " '##å¡': 14843,\n",
       " '##ç‰Ÿ': 17340,\n",
       " '389': 12512,\n",
       " 'ã€…': 513,\n",
       " 'å±Ž': 2241,\n",
       " 'å»š': 2446,\n",
       " 'è²‚': 6503,\n",
       " 'youtube': 8487,\n",
       " '##å½†': 15548,\n",
       " 'æ“': 3075,\n",
       " '##é’Ÿ': 20221,\n",
       " '##é’°': 20234,\n",
       " '##ç€ž': 17168,\n",
       " '##é™': 20531,\n",
       " 'cma': 12398,\n",
       " '##ä»—': 13858,\n",
       " '##æ¯': 16737,\n",
       " '##ä¸‡': 13731,\n",
       " 'ç¥º': 4878,\n",
       " 'ã‚ã‚Šã¾ã™': 12737,\n",
       " 'sci': 11776,\n",
       " 'å¢': 1365,\n",
       " 'adam': 11194,\n",
       " 'å€š': 953,\n",
       " '##å’˜': 14535,\n",
       " 'æ‹”': 2869,\n",
       " '##æ¸Ž': 16989,\n",
       " 'éš˜': 7394,\n",
       " 'æ–‘': 3157,\n",
       " 'd3': 10966,\n",
       " '##ã„‡': 13707,\n",
       " '##è·¡': 19714,\n",
       " 'å‹': 1351,\n",
       " '##è’‚': 18938,\n",
       " 'æž‡': 3355,\n",
       " '##012': 12037,\n",
       " 'ds': 11274,\n",
       " '##éˆ‰': 20099,\n",
       " '##è½…': 19807,\n",
       " 'æ”ª': 3115,\n",
       " 'è„': 5553,\n",
       " '##éªœ': 20805,\n",
       " '##é¹…': 20957,\n",
       " '##è§¸': 19297,\n",
       " '2004': 8258,\n",
       " 'ç¹ª': 5257,\n",
       " '##å¸œ': 15426,\n",
       " '##ç–¼': 17620,\n",
       " 'safari': 8580,\n",
       " '##bay': 13200,\n",
       " 'è¯£': 6419,\n",
       " 'ç¼¢': 5363,\n",
       " 'å¾“': 2531,\n",
       " '##à¸¡': 13445,\n",
       " '##èº²': 19776,\n",
       " 'è¶': 6630,\n",
       " 'ä¼´': 845,\n",
       " '##åƒ–': 14068,\n",
       " '##ä¹ƒ': 13775,\n",
       " 'è‚ ': 5499,\n",
       " 'æŒº': 2923,\n",
       " '##å•¶': 14635,\n",
       " '##pn': 12991,\n",
       " '##ç¿°': 18489,\n",
       " '##ive': 8857,\n",
       " 'åŒ': 1398,\n",
       " 'â™¥yoyoâ™¥': 8948,\n",
       " '181': 10111,\n",
       " '##æ¾§': 17133,\n",
       " '##æ¾†': 17125,\n",
       " '##é‚¯': 19992,\n",
       " 'æ‹¡': 2878,\n",
       " 'eleven': 9795,\n",
       " 'copy': 11669,\n",
       " 'æ‹‰': 2861,\n",
       " 'æƒŠ': 2661,\n",
       " '##ation': 8794,\n",
       " '209': 10381,\n",
       " '##è¾†': 19832,\n",
       " '##cel': 11786,\n",
       " 'ç¯‰': 5064,\n",
       " 'amd': 8992,\n",
       " '1927': 9620,\n",
       " '378': 12770,\n",
       " '##è˜­': 19041,\n",
       " 'é“¸': 7214,\n",
       " '##æ›´': 16348,\n",
       " 'å½«': 2508,\n",
       " 'æ°': 2623,\n",
       " 'é„±': 6974,\n",
       " '##æºŸ': 17036,\n",
       " '##è´Ÿ': 19623,\n",
       " '##ç…¦': 17268,\n",
       " 'ç¢—': 4813,\n",
       " '##å§¦': 15063,\n",
       " 'æ„§': 2700,\n",
       " 'å­¸': 2119,\n",
       " '##æ‰°': 15874,\n",
       " '##æ’¼': 16129,\n",
       " 'Ñˆ': 256,\n",
       " 'font': 11851,\n",
       " '##æ€Ž': 15639,\n",
       " '##cl': 10753,\n",
       " '##æš´': 16331,\n",
       " '##åœ³': 14823,\n",
       " 'åª²': 2059,\n",
       " 'a7': 11226,\n",
       " '##èœ¿': 19122,\n",
       " '##è¿¥': 19886,\n",
       " 'they': 12013,\n",
       " '##å¹´': 15456,\n",
       " 'table': 10809,\n",
       " '##è²¶': 19581,\n",
       " 'å•Ÿ': 1564,\n",
       " 'è¯š': 6411,\n",
       " '##ç©—': 18007,\n",
       " '##sol': 12257,\n",
       " '##ice': 8877,\n",
       " '##è³': 19589,\n",
       " '##é˜‡': 20384,\n",
       " 'â”†': 432,\n",
       " '##å': 14467,\n",
       " '##ç¼…': 18404,\n",
       " '##é”': 20286,\n",
       " 'å›ª': 1734,\n",
       " '##é¢—': 20635,\n",
       " 'Ðº': 242,\n",
       " '##38': 9137,\n",
       " 'ebay': 8886,\n",
       " '##è½': 18853,\n",
       " 'ç¸½': 5244,\n",
       " '##å•²': 14633,\n",
       " 'åµ¬': 2320,\n",
       " '##å•': 14032,\n",
       " '##å†œ': 14150,\n",
       " 'è–„': 5946,\n",
       " 'final': 10591,\n",
       " '##å»ƒ': 15497,\n",
       " '##æ†š': 15790,\n",
       " 'puma': 11803,\n",
       " 'ktv': 8894,\n",
       " 'é¢—': 7578,\n",
       " 'ã«ã“': 13059,\n",
       " 'è¨´': 6260,\n",
       " '##ï¼ï¼': 9885,\n",
       " 'è±': 6485,\n",
       " 'php': 8531,\n",
       " 'sunday': 11548,\n",
       " '##ç’Ž': 17522,\n",
       " 'ç«™': 4991,\n",
       " 'æ€Ž': 2582,\n",
       " 'daily': 10210,\n",
       " 'èŒ': 5466,\n",
       " '##ä¸œ': 13748,\n",
       " '##é¢': 20186,\n",
       " 'kitchen': 11808,\n",
       " '##é¢–': 20634,\n",
       " 'å±œ': 2246,\n",
       " 'åš': 1780,\n",
       " 'èƒ¡': 5529,\n",
       " '##line': 8762,\n",
       " 'é´•': 7858,\n",
       " '##æœ•': 16362,\n",
       " '##æ®·': 16725,\n",
       " '##ç…Ž': 17260,\n",
       " '##uy': 12574,\n",
       " 'openload': 13096,\n",
       " '##è½': 18538,\n",
       " '##é´¦': 20917,\n",
       " 'æ»¸': 4019,\n",
       " '##é¤¡': 20687,\n",
       " 'shopping': 9662,\n",
       " 'ã‚·': 604,\n",
       " '##åˆ': 14027,\n",
       " 'å¶': 1428,\n",
       " 'å®': 2123,\n",
       " 'æ“': 3082,\n",
       " 'tcp': 9901,\n",
       " 'â–²topapr': 10162,\n",
       " '##id': 8601,\n",
       " '##è„‘': 18611,\n",
       " '##mi': 8625,\n",
       " 'æ•—': 3134,\n",
       " 'å…¬': 1062,\n",
       " 'æ±†': 3725,\n",
       " 'âˆ’': 377,\n",
       " 'è“': 5828,\n",
       " 'wang': 9660,\n",
       " '212': 10164,\n",
       " 'å¯“': 2171,\n",
       " '##ä¸Ÿ': 13751,\n",
       " '##è©': 19323,\n",
       " '##éƒ¤': 20010,\n",
       " 'è§‘': 6234,\n",
       " 'å˜–': 1654,\n",
       " 'åº¾': 2437,\n",
       " 'é‚±': 6937,\n",
       " 'ï¼': 8013,\n",
       " '##è‘«': 18929,\n",
       " '##æ´»': 16890,\n",
       " '##éŠ': 19936,\n",
       " 'æ¿Ÿ': 4089,\n",
       " 'è´¥': 6571,\n",
       " '2008': 8182,\n",
       " 'è¯ž': 6414,\n",
       " '##mn': 11919,\n",
       " '##å…–': 14110,\n",
       " 'oa': 10527,\n",
       " '##è¯¶': 19491,\n",
       " 'çª': 4407,\n",
       " 'è™Ž': 5988,\n",
       " 'é‡œ': 7035,\n",
       " '##fl': 11690,\n",
       " 'åž': 1302,\n",
       " 'ç»¥': 5324,\n",
       " '##å': 14458,\n",
       " '##ç†„': 17276,\n",
       " 'å‘': 1778,\n",
       " 'â‹¯': 403,\n",
       " 'æ¨¸': 3571,\n",
       " '##æ¯': 16735,\n",
       " 'è¼¯': 6744,\n",
       " 'g4g': 10613,\n",
       " 'ã®ãªã„ãƒ•ãƒ­ã‚¯ã«': 10900,\n",
       " '##å¼': 15523,\n",
       " 'ã€': 520,\n",
       " 'è‡´': 5636,\n",
       " '##æž«': 16424,\n",
       " '##é›ž': 20487,\n",
       " 'é²«': 7836,\n",
       " 'left': 12744,\n",
       " '##ä¸­': 13761,\n",
       " 'æ®¤': 3662,\n",
       " 'ç¬¦': 5016,\n",
       " '##ä¾¨': 13962,\n",
       " 'æ‚': 2926,\n",
       " 'è¨¥': 6255,\n",
       " '980': 10536,\n",
       " 'museum': 10553,\n",
       " 'panasonic': 10752,\n",
       " '##è«‹': 19370,\n",
       " '##é’ˆ': 20208,\n",
       " '##ã€“': 13660,\n",
       " ':': 131,\n",
       " 'ä¹ ': 739,\n",
       " '##å¦£': 15035,\n",
       " 'keep': 11654,\n",
       " '##ç»´': 18392,\n",
       " '##é¥¥': 20702,\n",
       " '##æ·©': 16970,\n",
       " '##ç¹”': 18308,\n",
       " 'å»': 2447,\n",
       " '013': 13034,\n",
       " '##aw': 10922,\n",
       " 'shop': 9926,\n",
       " '##ç¶': 18250,\n",
       " 'æ½”': 4049,\n",
       " 'æ†‹': 2728,\n",
       " 'è‘¦': 5870,\n",
       " '##è¨‚': 19299,\n",
       " 'ä¹ž': 737,\n",
       " '##å®°': 15210,\n",
       " '272': 11281,\n",
       " '##è«³': 19383,\n",
       " 'å½': 1389,\n",
       " 'å›‚': 1716,\n",
       " 'éƒ‘': 6948,\n",
       " '##å˜†': 14704,\n",
       " '555': 11723,\n",
       " '##ç¼‡': 18406,\n",
       " 'è¯': 6405,\n",
       " 'é§…': 7686,\n",
       " 'è¡¬': 6137,\n",
       " '1900': 8985,\n",
       " 'ç¨¹': 4939,\n",
       " 'æ¡¥': 3441,\n",
       " 'ç¦¦': 4888,\n",
       " 'tomtom': 12196,\n",
       " '##tra': 9808,\n",
       " '##è¿©': 19888,\n",
       " 'á„‰': 296,\n",
       " '##ties': 11199,\n",
       " '##å™±': 14751,\n",
       " 'hitachi': 12294,\n",
       " 'bmw': 8943,\n",
       " 'factory': 12896,\n",
       " 'adsl': 13080,\n",
       " 'éº': 7928,\n",
       " 'æ¶¯': 3889,\n",
       " 'vmalife': 10823,\n",
       " 'è¯¡': 6417,\n",
       " 'Ð¿': 247,\n",
       " 'airport': 11435,\n",
       " '##ough': 11600,\n",
       " '##ra': 8332,\n",
       " '##å–ª': 14660,\n",
       " '##3': 8152,\n",
       " 'é’º': 7182,\n",
       " '##ç‰‡': 17332,\n",
       " 'brake': 8550,\n",
       " 'festival': 11720,\n",
       " '##èœ“': 19109,\n",
       " '51': 8246,\n",
       " 'æ‚¶': 2653,\n",
       " '##ã‚Œã‚‹': 10273,\n",
       " 'ç¶¿': 5214,\n",
       " '##ann': 12464,\n",
       " '##ç›£': 17732,\n",
       " '##ç£Š': 17887,\n",
       " 'å´™': 2306,\n",
       " 'èª°': 6306,\n",
       " '##bs': 9071,\n",
       " 'xxx': 8790,\n",
       " 'ä¸¢': 696,\n",
       " '##ä¼¢': 13895,\n",
       " 'å…‡': 1043,\n",
       " 'é—Š': 7295,\n",
       " '##ç“¦': 17539,\n",
       " 'facebooktwitterpinterestgoogle': 11498,\n",
       " '##è¾': 19837,\n",
       " '##é–©': 20344,\n",
       " '##æº': 17031,\n",
       " 'è¸µ': 6683,\n",
       " 'æ«¸': 3606,\n",
       " '##ã®': 8227,\n",
       " 'å•ƒ': 1553,\n",
       " 'jr': 8602,\n",
       " 'vera': 9378,\n",
       " '##ï¼ˆ': 21077,\n",
       " '##èºº': 19777,\n",
       " '##å…¢': 14113,\n",
       " 'å„¿': 1036,\n",
       " 'magazine': 10469,\n",
       " '251': 10924,\n",
       " '##rder': 12658,\n",
       " '##ç™±': 17686,\n",
       " '023': 13244,\n",
       " 'å—ª': 1636,\n",
       " 'bo': 11059,\n",
       " 'æ»': 4004,\n",
       " '##èŽ±': 18869,\n",
       " '##è–©': 19015,\n",
       " 'é‚“': 6924,\n",
       " '##è­·': 19419,\n",
       " '##é™‚': 20409,\n",
       " 'éƒ·': 6961,\n",
       " '##çžŸ': 17797,\n",
       " 'è­‰': 6349,\n",
       " 'foundation': 12099,\n",
       " '##å§¬': 15067,\n",
       " 'å¸·': 2381,\n",
       " '##å€˜': 14008,\n",
       " 'ç†¹': 4231,\n",
       " '271': 11206,\n",
       " 'cnn': 9206,\n",
       " 'é…¯': 6994,\n",
       " '##ç©†': 18003,\n",
       " 'è¨¼': 6264,\n",
       " '##è–¯': 19018,\n",
       " '##è®¯': 19437,\n",
       " '##ä¸˜': 13744,\n",
       " '##&': 13322,\n",
       " '##ç’½': 17530,\n",
       " 'structure': 13286,\n",
       " 'Ëˆ': 202,\n",
       " '##ðŸ‘': 21124,\n",
       " 'è…ˆ': 5571,\n",
       " 'é¢Œ': 7571,\n",
       " 'é¤¨': 7631,\n",
       " 'jane': 11909,\n",
       " '[unused71]': 71,\n",
       " '##ang': 8688,\n",
       " 'eye': 11650,\n",
       " '66': 8347,\n",
       " 'è¾“': 6783,\n",
       " '##ã—ã¦': 9379,\n",
       " 'æ·ž': 3908,\n",
       " 'é‡': 7031,\n",
       " 'Ð²': 235,\n",
       " 'è¦': 6211,\n",
       " 'q10': 11382,\n",
       " '##ters': 12017,\n",
       " '##å­¸': 15176,\n",
       " 'åƒš': 1012,\n",
       " 'åš¥': 1710,\n",
       " 'é²¤': 7834,\n",
       " 'techorz': 12389,\n",
       " '##å¸½': 15441,\n",
       " '##çƒƒ': 17220,\n",
       " '##é‚‘': 19980,\n",
       " 'é¢¨': 7591,\n",
       " '##éº´': 20990,\n",
       " 'ã‹ã‹ã‚Šã¾ã™': 9791,\n",
       " '##ç¬¼': 18078,\n",
       " 'æŸ±': 3393,\n",
       " 'è—œ': 5970,\n",
       " '##æ¾ˆ': 17126,\n",
       " '##å‚²': 14057,\n",
       " '##å¯“': 15228,\n",
       " '##æ§': 16594,\n",
       " 'sk': 9820,\n",
       " '##è¨': 19309,\n",
       " 'æ½': 3005,\n",
       " 'ç¾Œ': 5400,\n",
       " '##ç¶´': 18264,\n",
       " '##king': 9740,\n",
       " '299': 9600,\n",
       " '##wer': 10668,\n",
       " 'ultra': 10893,\n",
       " 'ç„—': 4187,\n",
       " '##å¥•': 15002,\n",
       " 'è˜Š': 5980,\n",
       " '##å¨˜': 15080,\n",
       " '##op': 9133,\n",
       " '##å‡¿': 14199,\n",
       " 'ç¿³': 5434,\n",
       " 'ç…': 4353,\n",
       " '##è¼”': 19794,\n",
       " 'é²‘': 7829,\n",
       " 'é”†': 7223,\n",
       " 'london': 9978,\n",
       " 'å…»': 1075,\n",
       " '\"': 107,\n",
       " 'å‚£': 994,\n",
       " 'æ¼¿': 4043,\n",
       " 'balance': 11606,\n",
       " 'éŸŒ': 7501,\n",
       " '##ç±³': 18158,\n",
       " 'bar': 9054,\n",
       " '##â–ª': 13607,\n",
       " '##é‰—': 20116,\n",
       " 'æ‰ª': 2811,\n",
       " '##è‡': 19123,\n",
       " 'ç¼ª': 5368,\n",
       " 'åŽ•': 1329,\n",
       " 'junior': 12552,\n",
       " 'åœ§': 1761,\n",
       " '##ç”¥': 17555,\n",
       " '##ç•': 17576,\n",
       " '##ç»“': 18367,\n",
       " '##ru': 10409,\n",
       " 'ferragamo': 9992,\n",
       " 'å’': 1293,\n",
       " '##è”¼': 18985,\n",
       " '##èª‡': 19345,\n",
       " 'ã‚ã¦': 11967,\n",
       " 'a6': 11716,\n",
       " 'å²˜': 2267,\n",
       " '##å—': 14355,\n",
       " 'works': 13112,\n",
       " 'ãˆ¦': 667,\n",
       " 'lab': 11441,\n",
       " 'kim': 10683,\n",
       " '##sco': 11364,\n",
       " '##âˆŸ': 13534,\n",
       " 'è™«': 6001,\n",
       " 'å‰‚': 1177,\n",
       " '##fr': 13245,\n",
       " '##Ð»': 13410,\n",
       " 'è›‡': 6026,\n",
       " '##ä¼¸': 13904,\n",
       " 'çŒ´': 4347,\n",
       " '##æ³®': 16860,\n",
       " '##ç‚…': 17196,\n",
       " 'éš': 7475,\n",
       " 'æ°': 3695,\n",
       " '##æ¼': 17079,\n",
       " '##å¹„': 15444,\n",
       " '##æ¸­': 17005,\n",
       " 'å……': 1041,\n",
       " '##è‡´': 18693,\n",
       " 'é’™': 7159,\n",
       " '##è¨£': 19311,\n",
       " '##wo': 10911,\n",
       " '1926': 10126,\n",
       " 'æ¿¡': 4091,\n",
       " 'é‚ˆ': 6919,\n",
       " '##ç¸': 17423,\n",
       " '##03': 9042,\n",
       " 'joseph': 11151,\n",
       " '##å…¬': 14119,\n",
       " 'çœž': 4695,\n",
       " 'ç': 4398,\n",
       " '30': 8114,\n",
       " '215': 10082,\n",
       " '##oz': 13102,\n",
       " 'Ð·': 240,\n",
       " '417': 13038,\n",
       " 'åƒ': 1007,\n",
       " 'cool1': 12032,\n",
       " '##å¤ª': 14979,\n",
       " 'é™©': 7372,\n",
       " '##ube': 10957,\n",
       " 'å·¨': 2342,\n",
       " 'æ²¾': 3783,\n",
       " '##é„²': 20032,\n",
       " '##é…—': 20041,\n",
       " '##é˜': 20189,\n",
       " '##ors': 10903,\n",
       " '##å©': 15094,\n",
       " '##å‘¸': 14516,\n",
       " 'æ¢': 3451,\n",
       " '##0': 8129,\n",
       " 'longchamp': 9003,\n",
       " 'mcu': 10738,\n",
       " '##å•ž': 14620,\n",
       " 'é': 6884,\n",
       " '##æ§': 16600,\n",
       " 'çˆ¾': 4273,\n",
       " 'ä»¶': 816,\n",
       " '##æ¹«': 17021,\n",
       " '##ç´Š': 18207,\n",
       " 'åŒ': 1352,\n",
       " 'ç–²': 4558,\n",
       " 'èŸ„': 6092,\n",
       " 'sex': 11288,\n",
       " 'wu': 10552,\n",
       " 'money': 10348,\n",
       " '##æ ‡': 16460,\n",
       " '##æš„': 16315,\n",
       " 'é‡': 7036,\n",
       " '##ç¿¡': 18486,\n",
       " '##æ¿•': 17143,\n",
       " 'å¥š': 1949,\n",
       " '##å·«': 15401,\n",
       " 'æ±‰': 3727,\n",
       " 'è”¬': 5922,\n",
       " 'ces': 9818,\n",
       " 'sound': 12516,\n",
       " '##é€¢': 19921,\n",
       " '##é¥¨': 20703,\n",
       " '##ãƒ½': 13704,\n",
       " '##æ²»': 16837,\n",
       " 'ï½—': 8073,\n",
       " '1400': 9439,\n",
       " '##è¶•': 19691,\n",
       " 'é˜‰': 7329,\n",
       " 'ç·´': 5230,\n",
       " 'coc': 11917,\n",
       " '##æ¥': 15672,\n",
       " '##=': 13335,\n",
       " '##dm': 10420,\n",
       " 'è ±': 6113,\n",
       " 'access': 11098,\n",
       " '##è”µ': 18981,\n",
       " 'è¯²': 6431,\n",
       " 'é¥•': 7642,\n",
       " '##è‘©': 18928,\n",
       " '##æ¿': 16409,\n",
       " 'éž£': 7496,\n",
       " '##éž¦': 20554,\n",
       " 'é ˆ': 7519,\n",
       " '##ä»Š': 13848,\n",
       " 'Ù„': 269,\n",
       " 'èˆœ': 5658,\n",
       " '##ç¢': 17775,\n",
       " '##å”': 14594,\n",
       " 'è•ƒ': 5931,\n",
       " '##le': 8268,\n",
       " 'grand': 9968,\n",
       " 'çª': 4427,\n",
       " '##ene': 10600,\n",
       " 'urn': 11584,\n",
       " '##é£™': 20661,\n",
       " '##é¹‰': 20959,\n",
       " '##é¸¦': 20944,\n",
       " '##ç»¿': 18401,\n",
       " '[unused80]': 80,\n",
       " 'rosie': 10487,\n",
       " 'åª': 1790,\n",
       " '##ç‚¼': 17216,\n",
       " '##ç»¡': 18378,\n",
       " 'éŸ‹': 7500,\n",
       " '##à¸¢': 13446,\n",
       " 'å¤©': 1921,\n",
       " '##æ„‰': 15747,\n",
       " '##tant': 12028,\n",
       " '##come': 12097,\n",
       " 'è±†': 6486,\n",
       " 'rose': 9497,\n",
       " '##å¥–': 15003,\n",
       " 'æŽ¢': 2968,\n",
       " '##ãƒ¦': 13698,\n",
       " '##ç¦„': 17939,\n",
       " 'è¸Ÿ': 6676,\n",
       " '##á„': 13455,\n",
       " '##å¤­': 14981,\n",
       " '##è°': 19500,\n",
       " '##çŠ’': 17359,\n",
       " '##ç¿Œ': 18479,\n",
       " 'èˆ«': 5662,\n",
       " 'é™ˆ': 7357,\n",
       " 'aaa': 10876,\n",
       " '##è•­': 18998,\n",
       " '##é£•': 20659,\n",
       " 'å¥”': 1944,\n",
       " 'ã„›': 658,\n",
       " 'è°¥': 6471,\n",
       " '##å¸': 14486,\n",
       " '##æ«¥': 16662,\n",
       " '4200': 12395,\n",
       " '##è€': 18496,\n",
       " 'v5': 11133,\n",
       " '##å™œ': 14743,\n",
       " '##å¢©': 14932,\n",
       " '##èŸ‹': 19151,\n",
       " 'ä¹': 726,\n",
       " '##cc': 8860,\n",
       " '356': 12215,\n",
       " 'èš‚': 6010,\n",
       " 'åœ»': 1768,\n",
       " 'å—£': 1632,\n",
       " '##åž¦': 14862,\n",
       " 'å—’': 1623,\n",
       " '##æ¬Š': 16666,\n",
       " '##å·®': 15402,\n",
       " 'mp4': 9399,\n",
       " 'city': 8869,\n",
       " '##å‡¦': 14186,\n",
       " 'ç‘¯': 4455,\n",
       " '##å¤”': 14967,\n",
       " 'msci': 9400,\n",
       " 'å‰': 1184,\n",
       " '293': 11855,\n",
       " 'æ´¼': 3834,\n",
       " '91': 8440,\n",
       " 'ç»¸': 5339,\n",
       " 'è¿‚': 6811,\n",
       " '##dt': 12672,\n",
       " '##å€Œ': 14001,\n",
       " 'ã‚ˆ': 577,\n",
       " '##ç»¶': 18394,\n",
       " 'ç·‹': 5216,\n",
       " '210': 9083,\n",
       " 'ç‡»': 4252,\n",
       " '##ä¸º': 13768,\n",
       " 'è¡†': 6120,\n",
       " '##é¥²': 20711,\n",
       " 'é™': 7360,\n",
       " '##ç“œ': 17535,\n",
       " '##é›¹': 20498,\n",
       " 'å†Š': 1084,\n",
       " '##ç­ ': 18092,\n",
       " 'eeworld': 12490,\n",
       " '##äºº': 13839,\n",
       " 'æ’²': 3067,\n",
       " 'tripadvisor': 8194,\n",
       " '##å‰Œ': 14240,\n",
       " '##ç˜‹': 17654,\n",
       " 'áµ‰': 331,\n",
       " 'ï½†': 8056,\n",
       " 'é£ª': 7612,\n",
       " '##å…­': 14120,\n",
       " '##å¢®': 14933,\n",
       " 'å‹µ': 1252,\n",
       " 'parker': 12495,\n",
       " '##ã€‚': 13646,\n",
       " 'å¾': 1434,\n",
       " 'ç­”': 5031,\n",
       " 'vsa': 10920,\n",
       " '##ï¼†': 21075,\n",
       " 'å“ª': 1525,\n",
       " '##é¢‚': 20620,\n",
       " 'å°': 2196,\n",
       " 'ç¾¸': 5415,\n",
       " '##ç¼š': 18416,\n",
       " '##ç¦': 17938,\n",
       " '177': 10132,\n",
       " 'æ»¥': 4010,\n",
       " 'é¢±': 7593,\n",
       " 'ç´§': 5165,\n",
       " '##â–Œ': 13603,\n",
       " '##æ¾¤': 17132,\n",
       " 'æ’ˆ': 3051,\n",
       " 'base': 11668,\n",
       " '##é¡Ž': 20598,\n",
       " '##é ¸': 20591,\n",
       " '##ing': 8221,\n",
       " '##å”„': 14590,\n",
       " 'board': 12020,\n",
       " '##æ€•': 15643,\n",
       " '##æ½œ': 17109,\n",
       " '##ç­›': 18090,\n",
       " '##æ ‘': 16466,\n",
       " 'è½¶': 6767,\n",
       " 'site': 11215,\n",
       " 'ä½“': 860,\n",
       " 'ieee': 12272,\n",
       " 'å¼­': 2481,\n",
       " 'é®': 6902,\n",
       " '##æº¯': 17042,\n",
       " '##èŽ‰': 18856,\n",
       " 'ol': 8972,\n",
       " 'tila': 10396,\n",
       " '##ç ’': 17833,\n",
       " '##é™°': 20431,\n",
       " 'éŽ”': 7114,\n",
       " '##å‡³': 14192,\n",
       " '##é ': 20536,\n",
       " 'gnu': 12367,\n",
       " 'è…¦': 5582,\n",
       " '##å´': 14036,\n",
       " '##ç¯‘': 18122,\n",
       " '##é£¢': 20666,\n",
       " '##çŽ‹': 17431,\n",
       " '##ä¼¦': 13897,\n",
       " 'l1': 12421,\n",
       " '##é™': 19948,\n",
       " 'into': 12609,\n",
       " '##é¥µ': 20713,\n",
       " '##â•®': 13592,\n",
       " '##æ³·': 16866,\n",
       " '##æ²ˆ': 16812,\n",
       " 'ã•ã‚Œã¾ã™': 12001,\n",
       " 'æ˜¨': 3219,\n",
       " '##dget': 11857,\n",
       " 'é·': 6907,\n",
       " '##å›­': 14793,\n",
       " '##ç§†': 17959,\n",
       " '##é‡µ': 20097,\n",
       " 'åŠ': 1210,\n",
       " 'union': 12161,\n",
       " '##é': 19941,\n",
       " 'ä½': 869,\n",
       " 'çº': 4436,\n",
       " 'æ‰”': 2803,\n",
       " '##tail': 11662,\n",
       " 'santa': 12321,\n",
       " 'jing': 13207,\n",
       " '##æ•': 16195,\n",
       " 'ç¼´': 5373,\n",
       " 'é–±': 7288,\n",
       " 'é¡µ': 7552,\n",
       " 'roger': 13033,\n",
       " '##æ¸£': 16999,\n",
       " '##ã£ã¦': 9067,\n",
       " '##è´': 19621,\n",
       " '##é¢…': 20622,\n",
       " 'æ±™': 3732,\n",
       " 'è³‚': 6533,\n",
       " '##ition': 11418,\n",
       " '##é¥Œ': 20695,\n",
       " '##à¸­': 13448,\n",
       " '##á„€': 13454,\n",
       " '##å¯§': 15237,\n",
       " 'æ¦­': 3531,\n",
       " '##ç€˜': 17164,\n",
       " '##ble': 8862,\n",
       " '##è€': 18877,\n",
       " 'é’©': 7174,\n",
       " '##ca': 8808,\n",
       " 'è‚ƒ': 5484,\n",
       " 'è§’': 6235,\n",
       " '246': 11003,\n",
       " 'say': 10114,\n",
       " 'c3': 11829,\n",
       " '444': 12876,\n",
       " 'Î³': 212,\n",
       " '##æ¯¯': 16748,\n",
       " 'é•¯': 7265,\n",
       " '##cca': 13144,\n",
       " '##ming': 10693,\n",
       " 'æ¸¸': 3952,\n",
       " '##ics': 9034,\n",
       " 'åž£': 1804,\n",
       " 'é¢': 7481,\n",
       " '##mw': 11504,\n",
       " '##é’§': 20229,\n",
       " '##å†•': 14146,\n",
       " '1m': 12103,\n",
       " 'ç†±': 4229,\n",
       " 'æˆ¾': 2790,\n",
       " '##ç³': 18186,\n",
       " 'his': 10163,\n",
       " 'å˜': 1299,\n",
       " '##æŽº': 16039,\n",
       " 'èŒ„': 5746,\n",
       " 'è¹™': 6694,\n",
       " '##èŠœ': 18754,\n",
       " 'â–²topoct': 10135,\n",
       " 'ç›¥': 4677,\n",
       " 'é€»': 6872,\n",
       " 'é¦': 7483,\n",
       " '08': 8142,\n",
       " 'ç‘•': 4442,\n",
       " 'é„': 7469,\n",
       " 'ãã‚’': 10995,\n",
       " '##ç¹†': 18305,\n",
       " 'ç–¾': 4565,\n",
       " '##æ‘¹': 16101,\n",
       " 'éª¨': 7755,\n",
       " '##è½¦': 19813,\n",
       " 'é ˜': 7526,\n",
       " '##ä¼½': 13907,\n",
       " 'å': 1402,\n",
       " 'åŸº': 1825,\n",
       " 'ç¾²': 5414,\n",
       " '##äºž': 13822,\n",
       " '##æ³¨': 16857,\n",
       " 'ï¾': 8097,\n",
       " '##éŒ¦': 20150,\n",
       " '##å™¬': 14750,\n",
       " 'ç¦º': 4894,\n",
       " 'è˜': 5470,\n",
       " '##áƒ¦': 13453,\n",
       " 'å¡': 1305,\n",
       " '2600': 10496,\n",
       " 'è²¿': 6530,\n",
       " 'åˆ¤': 1161,\n",
       " 'ib': 12487,\n",
       " '##ãƒŠãƒ¼': 12005,\n",
       " 'wear': 12679,\n",
       " 'é‹¼': 7086,\n",
       " '##å¢…': 14920,\n",
       " '##å§': 15060,\n",
       " '##æŒ¤': 15972,\n",
       " '398': 11425,\n",
       " '##ne': 8354,\n",
       " 'è¶¾': 6644,\n",
       " 'é„™': 6968,\n",
       " '122': 9203,\n",
       " '##èˆ': 18707,\n",
       " '325': 10838,\n",
       " '##qi': 11451,\n",
       " 'æ²®': 3775,\n",
       " 'è“¬': 5908,\n",
       " '##æ‰¯': 15873,\n",
       " '##æ‹Ž': 15922,\n",
       " '##è‰': 19125,\n",
       " '##berg': 10039,\n",
       " 'sdk': 10302,\n",
       " '##ç€‹': 17160,\n",
       " 'ç“´': 4485,\n",
       " 'åœŸ': 1759,\n",
       " 'é±¼': 7824,\n",
       " 'é': 6875,\n",
       " '##is': 8331,\n",
       " 'miacare': 11918,\n",
       " 'rx': 12342,\n",
       " '##2': 8144,\n",
       " '##ç®€': 18099,\n",
       " 'çœ ': 4697,\n",
       " '[unused96]': 96,\n",
       " '##å¦ž': 15034,\n",
       " 'apr': 9011,\n",
       " '##ism': 10627,\n",
       " '15058': 12347,\n",
       " 'æµ†': 3841,\n",
       " 'pokemon': 8934,\n",
       " '##å›—': 14779,\n",
       " 'çŠ¸': 4309,\n",
       " 'm8': 10914,\n",
       " '##ã„›': 13716,\n",
       " 'çˆ': 4256,\n",
       " '##èœ†': 19103,\n",
       " '##è¯·': 19492,\n",
       " '##æ‘³': 16099,\n",
       " '##ç–¯': 17613,\n",
       " 'h5': 9354,\n",
       " '##ç°§': 18139,\n",
       " '142': 9621,\n",
       " '##å°¤': 15272,\n",
       " '##è«§': 19378,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21128"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4 ç´¢å¼•è½¬æ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†è¯åºåˆ—è½¬æ¢ä¸ºidåºåˆ—\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['å¼±', 'å°', 'çš„', 'æˆ‘', 'ä¹Ÿ', 'æœ‰', 'å¤§', 'æ¢¦', 'æƒ³', '!']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†idåºåˆ—è½¬æ¢ä¸ºtokenåºåˆ—\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'å¼± å° çš„ æˆ‘ ä¹Ÿ æœ‰ å¤§ æ¢¦ æƒ³!'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†tokenåºåˆ—è½¬æ¢ä¸ºstring\n",
    "str_sen = tokenizer.convert_tokens_to_string(tokens)\n",
    "str_sen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  æ›´ä¾¿æ·çš„å®žçŽ°æ–¹å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºidåºåˆ—ï¼Œåˆç§°ä¹‹ä¸ºç¼–ç \n",
    "ids = tokenizer.encode(sen, add_special_tokens=True)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] å¼± å° çš„ æˆ‘ ä¹Ÿ æœ‰ å¤§ æ¢¦ æƒ³! [SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°†idåºåˆ—è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œåˆç§°ä¹‹ä¸ºè§£ç \n",
    "str_sen = tokenizer.decode(ids, skip_special_tokens=False)\n",
    "str_sen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5 å¡«å……ä¸Žæˆªæ–­"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¡«å……\n",
    "ids = tokenizer.encode(sen, padding=\"max_length\", max_length=15)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 102]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æˆªæ–­\n",
    "ids = tokenizer.encode(sen, max_length=5, truncation=True)\n",
    "ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6 å…¶ä»–è¾“å…¥éƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = tokenizer.encode(sen, padding=\"max_length\", max_length=15)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask = [1 if idx != 0 else 0 for idx in ids]\n",
    "token_type_ids = [0] * len(ids)\n",
    "ids, attention_mask, token_type_ids"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7 å¿«é€Ÿè°ƒç”¨æ–¹å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer.encode_plus(sen, padding=\"max_length\", max_length=15)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 106, 102, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(sen, padding=\"max_length\", max_length=15)\n",
    "inputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step8 å¤„ç†batchæ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 3457, 2682, 102], [101, 3300, 3457, 2682, 6443, 6963, 749, 679, 6629, 102], [101, 6841, 6852, 3457, 2682, 4638, 2552, 8024, 3683, 3457, 2682, 3315, 6716, 8024, 3291, 1377, 6586, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sens = [\"å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§æ¢¦æƒ³\",\n",
    "        \"æœ‰æ¢¦æƒ³è°éƒ½äº†ä¸èµ·\",\n",
    "        \"è¿½é€æ¢¦æƒ³çš„å¿ƒï¼Œæ¯”æ¢¦æƒ³æœ¬èº«ï¼Œæ›´å¯è´µ\"]\n",
    "res = tokenizer(sens)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31.2 ms\n",
      "Wall time: 34.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªçŽ¯å¤„ç†\n",
    "for i in range(1000):\n",
    "    tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 15.6 ms\n",
      "Wall time: 36.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = tokenizer([sen] * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='./roberta_tokenizer/', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast / Slow Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = \"å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§Dreaming!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fast_tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\")\n",
    "fast_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizer(name_or_path='uer/roberta-base-finetuned-dianping-chinese', vocab_size=21128, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slow_tokenizer = AutoTokenizer.from_pretrained(\"uer/roberta-base-finetuned-dianping-chinese\", use_fast=False)\n",
    "slow_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 141 ms\n",
      "Wall time: 310 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªçŽ¯å¤„ç†\n",
    "for i in range(10000):\n",
    "    fast_tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 453 ms\n",
      "Wall time: 864 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å•æ¡å¾ªçŽ¯å¤„ç†\n",
    "for i in range(10000):\n",
    "    slow_tokenizer(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 438 ms\n",
      "Wall time: 77.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = fast_tokenizer([sen] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 281 ms\n",
      "Wall time: 717 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# å¤„ç†batchæ•°æ®\n",
    "res = slow_tokenizer([sen] * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 2483, 2207, 4638, 2769, 738, 3300, 1920, 10252, 8221, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'offset_mapping': [(0, 0), (0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 12), (12, 15), (15, 16), (0, 0)]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = fast_tokenizer(sen, return_offsets_mapping=True)\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.word_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "return_offset_mapping is not available when using Python tokenizers. To use this feature, change your tokenizer to one deriving from transformers.PreTrainedTokenizerFast. More information on available tokenizers at https://github.com/huggingface/transformers/pull/2674",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mslow_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yuyao\\miniconda3\\envs\\transformers\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2802\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2800\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2801\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2802\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[0;32m   2803\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2804\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Users\\yuyao\\miniconda3\\envs\\transformers\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2908\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2888\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2889\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   2890\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2905\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2906\u001b[0m     )\n\u001b[0;32m   2907\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2908\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   2909\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2910\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   2911\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2912\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2913\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   2914\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2915\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2916\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2917\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2918\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2919\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2920\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2921\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2922\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2923\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2924\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2925\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2926\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2927\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yuyao\\miniconda3\\envs\\transformers\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2981\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2971\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   2972\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   2973\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   2974\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2978\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   2979\u001b[0m )\n\u001b[1;32m-> 2981\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_plus(\n\u001b[0;32m   2982\u001b[0m     text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   2983\u001b[0m     text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   2984\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   2985\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   2986\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   2987\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   2988\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   2989\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   2990\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   2991\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   2992\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   2993\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   2994\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   2995\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   2996\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   2997\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   2998\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   2999\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3000\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yuyao\\miniconda3\\envs\\transformers\\lib\\site-packages\\transformers\\tokenization_utils.py:711\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._encode_plus\u001b[1;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m    705\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    706\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not valid. Should be a string, a list/tuple of strings or a list/tuple of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    707\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m integers.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_offsets_mapping:\n\u001b[1;32m--> 711\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    712\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_offset_mapping is not available when using Python tokenizers. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    713\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo use this feature, change your tokenizer to one deriving from \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    714\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransformers.PreTrainedTokenizerFast. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    715\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMore information on available tokenizers at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    716\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://github.com/huggingface/transformers/pull/2674\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    717\u001b[0m     )\n\u001b[0;32m    719\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text)\n\u001b[0;32m    720\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(text_pair) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: return_offset_mapping is not available when using Python tokenizers. To use this feature, change your tokenizer to one deriving from transformers.PreTrainedTokenizerFast. More information on available tokenizers at https://github.com/huggingface/transformers/pull/2674"
     ]
    }
   ],
   "source": [
    "inputs = slow_tokenizer(sen, return_offsets_mapping=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç‰¹æ®ŠTokenizerçš„åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SkyworkTokenizer(name_or_path='Skywork/Skywork-13B-base', vocab_size=65519, model_max_length=1000000000000000019884624838656, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# æ–°ç‰ˆæœ¬çš„transformersï¼ˆ>4.34ï¼‰ï¼ŒåŠ è½½ THUDM/chatglm ä¼šæŠ¥é”™ï¼Œå› æ­¤è¿™é‡Œæ›¿æ¢ä¸ºäº†å¤©å®«çš„æ¨¡åž‹\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Skywork/Skywork-13B-base\", trust_remote_code=True)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('skywork_tokenizer\\\\tokenizer_config.json',\n",
       " 'skywork_tokenizer\\\\special_tokens_map.json',\n",
       " 'skywork_tokenizer\\\\tokenizer.model',\n",
       " 'skywork_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"skywork_tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"skywork_tokenizer\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>å¼±å°çš„æˆ‘ä¹Ÿæœ‰å¤§Dreaming!'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.encode(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
